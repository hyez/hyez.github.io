---
title:  "[리뷰] Algorithmic Bias and Fairness"
categories:
  - Review
tags:
  - Blog
---


## 💡 Bias란 무엇일까?

<img src='/assets/posts/스크린샷_2021-10-20_오후_2.08.18.png' width=300>
<img src='/assets/posts/스크린샷_2021-10-20_오후_2.10.42.png' width=300>

왼쪽 사진을 보고 이 사진이 무엇이냐고 물으면, 대부분의 사람들은 `watermelon` 이라고 대답할 것이다. 하지만, 오른쪽 사진을 보고 같은 질문에 대한 대답으로 `yellow watermelon` 이라고 대답할 것이다. 왜 첫번째 사진을 보고 `red watermelon`이라고 말하지 않을까? 
우리는 수박의 색을 당연하게 빨간색으로 생각한다. (즉, `red`는 수박의 `prototypical color`이다.) 따라서 첫번째 사진에 굳이 `red`를 붙이지 않는 것이다. 



## 💡 용어 정리
bias, stereotype은 **human or AI system**에 의해 발생한다.

1. `Prototype` : typical representation of a concept or object (e.g. 위의 예시에서 수박의 색을 red라고 생각하는 것)
2. `Bias` : 데이터 내에 있는 모든 정보를 고려하지 않음으로 인해, 지속적으로 잘못된 것들을 학습하는 경향
3. `Stereotype` 

## 💡 Bias 종류
Bias는 크게 `data-driven`과 `interpretation-driven`으로 나눌 수 있다. 


1. **Data-Driven**
    - `Selection Bias` : data selection 시 발생하는 bias (e.g. class imbalacne)
    - `Reporting Bias` : real likelihood를 다 반영할 수 없음 (e.g. news coverage)
    - `Sampling Bias` : 특정 data가 더 많이 샘플링되는 경우 (e.g. hair, skin tone)
2. **Interpretation-Driven**
    - `Correlation Fallacy` : correlation ≠ causation
    - `Over-generalization` : "general"을 평가하기위해 limited test data만 사용하기 때문에 발생
    - `Automation Bias` : human-generated 보다 AI-generated를 선호하고 human-generated를 무시하는 경향

## 💡 Fairness 정의
```markdown
Fairness를 정의하는 방법은 다양하지만, 본 강의에서는 `Equal Opportunity`를 기반으로 하는 정의를 설명한다.
이 외에도 `Equalized Odds`, `Demographic Parity` 등의 Fairness 정의가 존재한다. 
```

$f_{\theta}(x)$가 classifer 일때, `sensitive feature` $z$ 에 따라서 결과가 바뀌면 $f_{\theta}(x)$는 biased!


반대로, 아래 수식을 만족하면 $f$는 $z$ 에 관해 fair하다고 말할 수 있다. 
$$f_{\theta}(x) = f_{\theta}(x, z)$$

아래는 $z$ 가 single variable 일때, fairness 정의를 보여주고 있다. ($z$의 값이 바뀌더라도, 결과는 동일한 것을 의미함)

![스크린샷 2021-10-20 오후 3.32.21.png](/assets/posts/스크린샷_2021-10-20_오후_3.32.21.png)

## 💡 Tehchniques to Improve Fairness
```markdown
Fairness 개선을 위해 문제가 되는 feature를 제거하거나 새로운 feature를 추가하는 방법이 있다.
```

1. **Bias Mitigation (Remove)**
    - Biased model, dataset, .. 
    → **Remove** problematic signal 
    → Mitigated bias & Improved fairness
2. **Inclusion (Add)**
    - Biased model, dataset, .. 
    → **Add** signal for desired features 
    → Re-weighted signal & Improved fairness

## 💡 Bias Mitigation

1. **Adversarial multi-task learning** 
    - jointly predict output $y$(class label) and $z$(sensitive attribute)
    
    ![스크린샷 2021-10-20 오후 4.08.15.png](/assets/posts/스크린샷_2021-10-20_오후_4.08.15.png)
    
2. **Learned latnet structure**
    - Learn latent structure → Estmiate distribution → Adaptively resample data → Learn from fair data distribution
        
        ![스크린샷 2021-10-20 오후 4.16.10.png](/assets/posts/스크린샷_2021-10-20_오후_4.16.10.png)
        
    

---

## References

- [https://www.youtube.com/watch?v=wmyVODy_WD8](https://www.youtube.com/watch?v=wmyVODy_WD8)