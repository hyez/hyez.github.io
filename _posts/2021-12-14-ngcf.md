---
title:  "[Paper Review] Neural Graph Collaborative Filtering"
toc: true
categories:
  - Study
  - Paper
  - Recommendations
tags:
  - Review 
---

> NGCF: Neural Graph Collaborative Filtering (SIGIR '19) 논문 리뷰입니다.


## 1. Introduction

- CF 모델 (MF, NCF 등)의 문제점 → collaborative signal이 부족함
    - `collaborative signal` : user-item interaction을 표현하는 latent vector
- 본 논문에선 user-item interaaction으로 부터 high-order connectivity를 다루고, graph structure로 collaborative signal을 인코딩함으로써 위의 문제를 해결함

### Running Example

![Untitled](%5B3%5D%20(NGCF)%20Neural%20Graph%20Collaborative%20Filtering%20(S%20cf95bafe931848ee89dac7c69d801b73/Untitled.png)

- **user-item interaction graph**
    - u1은 3개의 item과 interaction
- **high-order connectivity for u1**
    - path length l이 1보다 커질때를 보여줌
    - l=1일때는 u1이 interaction한 i1, i2, i3
    - l=2일때는 그 item(i1, i2, i3)과 interaction한 u2, u3
    - l=3일때는 그 user(u2, u3)와 interaction한 i4, i5, i4를 각각 그릴 수 있음
- **high-order connectivity가 의미하는 것은?**
    - **path u1 ← i2 ← u2** : u1과 u2의 similarity를 나타냄 (같은 item i2를 소비했으므로)
    - **path u1 ← i2 ← u2 ← i4** : u1이 i4를 선호할 거 같다는 것을 의미함 (u1과 비슷한 u2가 i4를 소비했으므로)
    - l=3에서 u1은 i5보다 i4를 선호할 것!
        - <i4, u1>은 2개의 path를 가진 반면, <i5, u1>은 1개의 path를 가지고 있기 때문

### Embedding Propagation

- high-order connectivity를 embedding function으로 modeling
- 즉, interaction graph를 확장하는 것이 아니라, embedding propagation layer를 통해 interact된 item or user의 embedding을 aggregating함
- 여러개의 embedding propagation layer를 `stacking`함으로써 high-order connectivity에서 collaborative signal 포착함
    - stacking two layers : u1 ← i2 ← u2 에서 behavior similarity 포착 (e.g. u1과 u2의 유사도)
    - stacking three layers : u1 ← i2 ← u2 ← i4 에서 potential recomendations (e.g. i4를 추천해줄것인지) 및 recommendation priority (e.g. i5보다 i4를 더 선호하는지) 포착

### Contributions

- model-based CF methods에서 embedding function에서 collaboriative signal을 명시적으로 활용하는 것에 대한 중요성 강조
- NGCF 제안, 명시적으로 collaborative signal을 high-order connectivity의 형태로 encoding (by performing embedding propagation)
- empirical studies on three million-size datasets

---

## 2. Methodology

![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%201.png)

- three components
    - **embedding layer**
        - initialization of user embeddings and item embeddings
    - **multiple embedding propagation layers**
        - high-order connectivity relations
    - **prediction layer**
        - aggregates the refined embeddings from different propagation layers
        - outputs the affinity score of a user-item pair

### 2.1 Embedding Layer

![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%202.png)

- traditional recommender systems (e.g. MF, NCF) 에서는 embedding layer가 바로 interaction layer로 들어감
- 반면 NGCF에서는 propagation layer를 거쳐서 user-item interaction graph 적용

### 2.2 Embedding Propagation Layers

![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%203.png)

- **First-order Propagation**
    - `Message Construction`
        
        ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%204.png)
        
        ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%205.png)
        
        - general message form은 식 (2), 본 논문에선 식 (3)으로 정의함
        - $e_i$의 contribution도 보고, $e_i$와 $e_u$의 interaction도 봄
            - model representation ability 증가, 추천 성능 증가 (Section 4.4.2에서 보여줌)
        - $p_{ui}$는 graph Laplacian norm으로 설정
            - 얼마나 많은 historical item이 유저 선호도에 기여하는지를 반영
            - discount factor로 해석됨
        
    - `Message Aggregation`
        
        ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%206.png)
        
        - user u의 이웃들로부터 전파된 message들을 aggregate하는 단계! → user u의 first embedding propagation layer에서의 representation을 생성함
        - u의 이웃들로부터 전파된 message들과 u의 self-conncection을 더해서 activation function(여기선 LeackyReLU) 거쳐서 내보냄
            - self-connection of u : $m_{u←u} = W_1e_u$
            - W1은 식 (3)에서 사용된 weight matrix
        - $e_i^{(1)}$ 도 이와 마찬가지로 connected users로부터 정보를 propagating함으로써 얻을 수 있음
    
- **High-order Propagation**
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%207.png)
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%208.png)
    
    - embedding propagation layer를 stacking 하면 high-order connectivity를 표현할 수 있음
    - l개의 embedding propagation layer를 stacking 한다는 것 → **l-hop neighbors**로부터 propagate된 message를 받을 수 있다는 것을 의미함
    - 마찬가지로 layer l에서 item i의 representation도 얻을 수 있음
    - Figure 3에선 u1 ← i2 ← u2 ← i4의 embedding propagation process를 보여줌
        - 즉, i4로부터 message가 $e_{u1}^{(3)}$으로 명시적으로 인코딩됨 (이는 embedding propagation layer를 stacking함으로써 collaborative signal을 포착하는 것을 보여줌)

- Propagation Rule in Matrix Factorization
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%209.png)
    
    - 식 (5), (6)과 동일, matrix form으로 보면 다음과 같음
    - Laplacian matrix (식 (3)의 $p_{ui}$와 동일)
        
        ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%2010.png)
        
        - `R` : user-item interaction matrix
        - `D` : diagonal degree matrix (Dtt = |Nt|)
        

### 2.3 Model Prediction

- final embedding
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%2011.png)
    
    -  `||` : concatenation operation
    - concatenation 대신에 다른 agrregator 사용 가능함 (e.g., weighted average, max pooling, LSTM, etc.)

- user preference estimator
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%2012.png)
    

### 2.4 Optimization

- loss는 BPR 적용
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%2013.png)
    
- Model Size
    - 2개의 가중치 파라미터만 사용함
    - Gowalla dataset (20K users and 40K items)
        - MF가 .5 million parameters를 가진 반면, NGCF는 0.024 million additional parameters만 가짐
        - 매우 적은 파라미터로 high-order connectivity 포착
- Message and Node Dropout
    - overfitting 해결위해 dropout 도입
    - Message dropout
        - randomly drops out the outgoing messages (probability p1만큼 dropout)
    - Node dropout
        - For the l-th propagation layer, randomly drop (M + N )p2 nodes of the Laplacian matrix
    - training에만 적용, test 시엔 적용 X

### 2.5 Discussions

- **NGCF Generalizes SVD++**
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%2014.png)
    
    - SVD++는 high-order propagation layer가 없는 NGCF의 special case로 볼 수 있음
    - 따라서 NGCF에서 transformation matrix와 nonlinear activation function을 disable하면 SVD++를 만들 수 있음
    - 마찬가지로 FISM(item-based CF)도  $p_{iu'}$를 0으로 세팅하면 NGCF의 special case로 볼 수 있음
    
- **Time Complexity Analysis**
    
    ![Untitled](/assets/posts/2021-12-14-ngcf/Untitled%2015.png)
    
    - l-th propagation layer의 complexity와 prediction layer의 complexity 더함

---

## References

- [https://arxiv.org/pdf/1905.08108.pdf](https://arxiv.org/pdf/1905.08108.pdf)