---
title:  "[ë¦¬ë·°] Counteracting Bias and Increasing Fairness in Search and Recommender Systems"
toc: true
categories:
  - Review
tags:
  - Blog
---

> Recsys 2020 tutorial \<Counteracting Bias and Increasing Fairness in Search and Recommender Systems\>ì„ ë“£ê³  ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.

## Bias in Rankings

1. **Query "CEO"**
    - ê²€ìƒ‰ ê²°ê³¼ëŠ” ëŒ€ë¶€ë¶„ `white` & `male` ì¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-20 á„‹á…©á„’á…® 7.34.25.png](/assets/posts/ìŠ¤í¬ë¦°ìƒ·_2021-10-20_ì˜¤í›„_7.32.25.png)
    
2. **Query "why are black women so"**
    - ê²€ìƒ‰ ê²°ê³¼ëŠ” `angry`, `loud`, ..ìœ¼ë¡œ í¸í–¥ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
    
    ![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-20 á„‹á…©á„’á…® 7.32.25.png](/assets/posts/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-20_á„‹á…©á„’á…®_7.34.25.png)
    

### Why is this Problematic?

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-20 á„‹á…©á„’á…® 7.39.19.png](/assets/posts/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-20_á„‹á…©á„’á…®_7.39.19.png)

> ìœ„ ê·¸ë˜í”„ëŠ” ranking positionì— ë”°ë¥¸ CTRì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. top positionì— ìœ„ì¹˜í• ìˆ˜ë¡ ìœ ì €ê°€ ë” ë§ì´ í´ë¦­ì„ í•œë‹¤ëŠ” ê²ƒì¸ë°, ë†’ì€ ìˆœìœ„ì˜ ì•„ì´í…œì˜ CTRì€ ê³„ì†í•´ì„œ ë†’ì•„ì§ˆ ê²ƒì´ê³ , ë‚®ì€ ìˆœìœ„ì˜ ì•„ì´í…œì˜ CTRì€ ê³„ì†í•´ì„œ ë‚®ì•„ì§€ëŠ” í˜„ìƒì´ ìƒê¸´ë‹¤.
> 

## What is Bias?

> ì¶”ì²œì‹œìŠ¤í…œì—ì„œ biasëŠ” í¬ê²Œ `data bias`, `algorithmic bias`, `presentation bias`, `response bias`ë¡œ ë‚˜ë‰œë‹¤.
> 

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-20 á„‹á…©á„’á…® 7.49.39.png](/assets/posts/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-20_á„‹á…©á„’á…®_7.49.39.png)

### 1. Data Bias

- Cognitive bias
- Differenct group sizes
- Historical, cultural, educational, political reasons
- Sampling bias : íŠ¹ì • dataê°€ ë” ë§ì´ ìƒ˜í”Œë§ë˜ëŠ” ê²½ìš° (e.g. hair, skin tone)

### 2. Algorithmic Bias

- ëª¨ë¸ì€ real worldì—ì„œ ìƒ˜í”Œë§ëœ ë°ì´í„°ë¡œë§Œ í•™ìŠµí•˜ê¸°ë•Œë¬¸ì— biasê°€ ìƒê¸´ë‹¤.
- feature encoding, selection, training, evalaution ê³¼ì •ì—ì„œ ìƒê¸°ëŠ” bias

### 3. Presentation & Response Bias

- resultë¥¼ ì–´ë–»ê²Œ ë³´ì—¬ì¤„ ê²ƒì¸ì§€, ë­í‚¹ì„ ì–´ë–»ê²Œ í•˜ëŠ”ì§€ì— ë”°ë¼ì„œ ìƒê¸°ëŠ” bias

---

## What is Fair?

### ğŸ’¡ ìš©ì–´ ì •ë¦¬

- `Bias`
    - **skewed expousre**ë¥¼ ë§í•œë‹¤.
    - e.g. "CEO" ê²€ìƒ‰ ê²°ê³¼ top resultëŠ” ëŒ€ë¶€ë¶„ male & whiteì¸ ê²½ìš°
- `Diversity`
    - **ë‹¤ì–‘í•œ ê²°ê³¼**ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ ë§í•œë‹¤. (exposure of **multi-ascpects**)
    - e.g. "CEO" ê²€ìƒ‰ ê²°ê³¼ ë‹¤ì–‘í•œ genders, races, occupationsë¥¼ ë³´ì—¬ì£¼ëŠ” ê²½ìš°
- `Novelty`
    - ì¤‘ë³µëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ” ê²ƒì„ ë§í•œë‹¤. (**reduce** **redundancy**)
- `Fairness`
    - **pre-defined fairness**ì— ë”°ë¼ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ë‹¤.
    - ì´ë•Œ fairnessë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ê²Œ ì¡´ì¬í•œë‹¤.

### Fairness Definitions

Group fairnessëŠ” individulal fairnessë¥¼ ë³´ì¥í•˜ì§€ ì•Šì§€ë§Œ, individual fairnessëŠ” group fairnessë¥¼ ë³´ì¥í•œë‹¤. 

1. Individual fairness
    - Treat similar individuals similarly
    - e.g. 'ì—¬ì„±'ì´ë¼ëŠ” ê·¸ë£¹ íŠ¹ì„±ê³¼ëŠ” ê´€ê³„ X
2. Group fairness
    - ê´€ë ¨ëœ ê·¸ë£¹ë¼ë¦¬ ë‹¤ë£¨ëŠ” ê²ƒ
    - e.g. 'ì—¬ì„±'ì—ê²ŒëŠ” ë¹„ìŠ·í•˜ê²Œ ì¶”ì²œí•˜ëŠ” ê²½ìš°

### Statistical Parity

- **Demographic Parity**
$$P(d=1|a) = P(d=1)$$
    - decision dëŠ” sensitive attribute aì— ë…ë¦½ì ì´ë©´ â†’ fairness 
    - e.g. male or female ì´ë‘ì€ ê´€ê³„ X
- **Equalized Odd**
$$P(d=1|y=y, a) = P(d=1|y=y)$, y= {0, 1}$$
    - original labelì´ ê°™ì„ ë•Œ, decision dê°€ sensitive attribute aì— ë…ë¦½ì ì´ë©´ â†’ fairness
    - e.g. original labelì´ ê°™ë‹¤ë©´, male/femaleì€ ê´€ê³„ X

### Group Fairnes

- **Demographic Parity**
    - `group size proportion`ì„ resultì— ë°˜ì˜í•˜ëŠ” ê²ƒ
    - e.g. 80% male, 20% female CEOë¼ë©´ resultì— 80:20 ë°˜ì˜
- **Disparate Treatment**
    - `group utility`ë¥¼ resultì— ë°˜ì˜í•˜ëŠ”ê²ƒ (utilityëŠ” MAE, NDCG ê°™ì€ metricì„ ì˜ë¯¸)
- **Disparate Impact**
    - `expected group attention`(=outcome)ì„ resultì— ë°˜ì˜í•˜ëŠ” ê²ƒ

---

## Fairness-aware Strategies

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-21 á„‹á…©á„’á…® 2.53.54.png](/assets/posts/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-21_á„‹á…©á„’á…®_2.53.54.png)

### 1. Pre-processing

- **Remove bias** in data
    - e.g. sampling, balancing data, repairing data(re-labeling, remove disparate impact)

### 2. In-processing

- encode fairness **as part of the objective function**
    - e.g. regularizer

### 3. Post-processing

- **Fair presentation** of results
    - e.g. re-raniking, greedy approach, constraint, MAB

## Metrics for Fairness-aware Systems

### Utility Metrics

- user utility
- Decision support & accuarcy
    - MAE, precision, recall, F1, hit ratio
- Rank-biased
    - MRR, nDCG
- Diversity, novelty, intent-aware
    - Î±-nDCG, NRBP
    - ERR-IA, nDCG-IA

### Fairness Metrics

- Distribution- & proportion-based
    - NDKL
    - minSkew, maxSkiew (measure degree of bias)
- Error-based
- Fairness for probabilistic models

## Fairness Optimization

- utilityì™€ fairnessë¥¼ ë™ì‹œì— optimize

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-10-21 á„‹á…©á„’á…® 3.56.39.png](/assets/posts/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º_2021-10-21_á„‹á…©á„’á…®_3.56.39.png)

### Optimize Utility

- **[Given]** fairness constraint
- **[Goal]** maximize utility
    - e.g. maximize precision

### Optimize Fairness

- **[Given]** minimum utility threshold
- **[Goal]** maximize fairness
    - e.g. maximize entropy

### Joint Optimization

- **[Given]** trade-off between fairness and utility
- **[Goal]** maximize fairness and utility based on `trade-off`
    - e.g. maximize $f = w_1R + w_2E$
    

---

## References

- [https://www.youtube.com/watch?v=TtF6exuBbSU](https://www.youtube.com/watch?v=TtF6exuBbSU)