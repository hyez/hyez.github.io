---
title:  "[Paper Review] FairRec: Fairness-aware News Recommendation with Decomposed Adversarial Learning"
toc: true
categories:
  - Study
  - Paper
  - Recommendations
tags:
  - Review 
---

> FairRec: Fairness-aware News Recommendation with Decomposed Adversarial Learning (AAAI '21) 논문 리뷰입니다.

## **Abstract**

- propose to decompose the user interest model into two components.
    - aims to learn a **bias-aware** user embedding that captures the bias information on sensitive user attributes → attribute prediction task
    - aims to learn a **bias-free** user embedding that only encodes attribute-independent user interest information for fairness-aware news recommendation → adversarial learning
- orthogonality regularization method → distinguish the bias-free user embedding from the bias-aware one

---

## Introduction

- **Personalized news recommendation techniques**
    - representations of clicked news articles with a `GRU`
    - `personalized attention networks` to learn user representations from the representations of clicked news by using the embedding of user ID as attention query
    
- **Fig. 1**
    
    ![스크린샷 2021-11-19 오후 7.40.29.png](/assets/posts/스크린샷_2021-11-19_오후_7.40.29.png)
    
    - `gender bias`
        - **user interest models** can easily capture the these patterns and lead to some biases
        - **female use**r → may prefer fashion news
        - **male user** → may prefer sports news
    - heavily influenced by the biases brought by **sensitive user attributes** (e.g. gender)
        - female가  NBA를 좋아하더라도 click data 자체가 female users는 fashion을, male users는 NBA를 많이 선호 했으므로 female user에게는 NBA는 추천하지 못하는 현상이 발생함

- **fair**ness-aware news **rec**ommendation (FairRec)
    - with **decomposed adversarial learning** and **orthogonality regularization** → alleviate the unfairness
    - proposed to decompose the user interest model into two component
        - `attribute prediction task` : aims to learn a **bias-aware** user embedding that captures the bias information on sensitive user attributes (여기엔 more bias information)
        - `adversarial learning techniques` : aims to learn a **bias-free** user embedding that only encodes attribute-independent user interest information for fairness-aware news recommendation (여기선 sensitive attributes와 관련된 Information 제거)
    - **only use the bias-free user embedding** for personalized news ranking to achieve fairness-aware news recommendation
    - experiments on a benchmark news recommendation dataset

 

- **contributions**
    - propose **a fairness-aware news recommendation framework** → to improve fairness in news recommendation
    - propose **a decomposed adversarial learning method with orthogonality regularization** → to learn bias-free user embeddings
    - experiments on real-world dataset
    

---

## **Related Work**

### **News Recommendation**

- use a GRU network to learn user representations from the representations of clicked news (Okura et al. (2017))
- learn user representations based on the relevance between the representations of clicked and candidate news (Wang et al. (2018))
- learn user representations from clicked news via multi-head self-attention networks (Wu et al. (2019c))
- but, 얘네들은 다 fairness 잡지 못함 → 이 논문에서는 decomposed adversarial learning approach with orthogonality regularization 으로 해결하고자했음

### **Fairness-aware Recommendation**

- `provider-side fairness`
    - e.g. items from different providers have a fair chance of being recommended
- `customer-side fairness`
    - e.g. provide similar recommendations for users with different sensitive attributes
- studies
    - proposed **four different metrics** based on the predicted and real ratings of users with different attributes to measure unfairness (Yao and Huang (2017))
    - proposed to use probabilistic soft logic (PSL) rules to balance the ratings for both users in different groups by unbiasing the ratings for each item. (Farnadi et al. (2018))
    - several re-ranking rules(Geyik, Ambler, and Kentha- padi (2019))
- focus on the **fairness** of news recommendation results rather than accuracy

---

## **Methodology**

### **Problem Definition**

- target user `u`
- sensitive attribute `z`
- clicked `N` news articles
    - $D = \{D_1, D_2, ..., D_N\}$
- `M` candidate news set for this user
    - $D^c = \{D_1^c, D_2^c, ..., D_N^c\}$
- labels : target user u가 candiate news를 보는지
    - $[y_1 , y_2 , ..., y_M]$
- predicted values
    - $[\hat{y}_1 , \hat{y}_2 , ..., \hat{y}_M]$
    - candidate news는 이 값에 따라서 ranking됨
- top K ranked candidates
    - $D^r = \{D_{i1}^r, D_{i2}^r, ..., D_{iK}^r\}$

### **Framework of FairRec**

![스크린샷 2021-11-19 오후 8.26.58.png](/assets/posts/스크린샷_2021-11-19_오후_8.26.58.png)

- news and user models → based on NRMS (Wu et al. 2019c)
    
    ![스크린샷 2021-11-19 오후 8.45.28.png](/assets/posts/스크린샷_2021-11-19_오후_8.45.28.png)
    
    - **news model**
        - learns news representations from news titles
            - `multi-head self-attention network` to capture the contexts of words within a news title
            - `attentive pooling network` to learn news representations by modeling the importance of different words
    - **user model**
        - learns the representation of a target user u from her clicked news D
            - `news model` to learn the representations of these clicked news
            - `combination of multi-head self-attention network` and `attentive pooling network` to obtain the unified user representations
    - **fairness-aware news ranking score**
        - $\hat{y} = u^d·e^c$
    

### **Decomposed Adversarial Learning with Orthogonality Regularization**

- a core problem
    - how to learn the bias-free user embedding $u^d$ from users’ news click behaviors
    - but, same sensitive attribute를 가지는 유저들은 보통 비슷한 패턴을 가짐 (click behaviour) → 모델이 이런 패턴을 잡는 것은 쉬움 → 이런 biased pattern으로부터 bias-free user embeddings을 학습하면 됨
- Adversarial learning
    - learn bias-free deep representations from biased data
    - **maximally** informative for predicting the labels of the main task ↔ **minimally** discriminative for predicting sensitive attributes
        - 이를 통해 sensitive attribute에 대한 bias information를 제거함으로써 bias-free user embeddings 학습 가능함
- decompose the user interest model
    - `bias-aware` : learn bias-aware user embeddings that capture the bias information on sensitive user attribute
    - `bias-free` : only encodes the attribute-independent information of user interest into bias-free user embeddings
- **sensitive attribute prediction task**
    
    $\hat{z} = softmax(W^bu^b + b^b)$
    
    - crossentropy loss
        
        $L_G = -\frac{1}{U} \sum_{j=1}^{U} \sum_{i=1}^{C} z_i^j log(\hat{z}_i^j)$
        
        - probability of the j-th user’s attribute in the i-th class
        - U is the number of users.
- **main recommendation task**
    - apply adversarial learning to the bias-free user embedding (in order to eliminate the bias information)
    
    $\tilde{z} = softmax(W^du^d + b^d)$
    
    - adversarial loss function of the discriminator
        
        $L_A = -\frac{1}{U} \sum_{j=1}^{U} \sum_{i=1}^{C} z_i^j log(\tilde{z}_i^j)$
        
        - To avoid the discriminator from inferring user attributes from the bias-free user embedding, we use the **negative gradients of the discriminator** to penalize the model.
    - 하지만 bias-free embedding도 여전히 sensitive attribute에 대한 정보를 갖고있음
        - because the `discriminator` usually cannot perfectly infer the sensitive user attribute
- **orthogonality regularization method**
    - regularizes the bias-aware user embedding and bias-free user embedding
        - to be orthogonal to each other
    - loss function
        
        ![스크린샷 2021-11-20 오후 3.54.29.png](/assets/posts/스크린샷_2021-11-20_오후_3.54.29.png)
        

### **Model Training**

- *FairRec framework*
    - `bias-aware user embedding` mainly contains the information on sensitive user attribute
    - `bias-free user embedding` mainly encodes attribute-independent user interest information
    - 두 embedding 함께 사용 → $u = u^b + u^d$
    - $\hat{y} = u · e^c$
    - negative sampling techniques
        - For each candidate news clicked by a user, we randomly sample T negative news in the same session which are not clicked.
    - loss function for news recommendation (negative log-likelihood of the posterior click probability of clicked news)
        
        ![스크린샷 2021-11-20 오후 3.59.06.png](/assets/posts/스크린샷_2021-11-20_오후_3.59.06.png)
        
    - **final loss function**
        
        ![스크린샷 2021-11-20 오후 3.59.40.png](/assets/posts/스크린샷_2021-11-20_오후_3.59.40.png)