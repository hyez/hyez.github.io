---
title:  "[Paper Review] Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation"
toc: true
categories:
  - Review
  - Study
  - Paper
  - Recommendatinos
tags:
  - Review 
excerpt: "MetaHIN 논문 리뷰입니다"
---


## Introduction

![스크린샷 2021-10-24 오후 5.05.18.png](/assets/posts/스크린샷_2021-10-24_오후_5.05.18.png)

- HIN(Heterogeneous Information Network) - (a)
    - movie가 얼마나 actor, director랑 관련된지, user-movie interaction 등을 알아냄
    - `meta-paths` : 2개의 object의 relation sequence
        - User-Movie-Actor-Movie(UMAM) : user가 평가한 movie랑 같은 actor가 출연한 movie
- data-level - (b)
    - cold-start problem → content-based method로 해결
- model-level - (c)
    - cold-start problem → meta-learning으로 해결
    - meta-testing = cold-start user (with only one movie rating)
    - meta-training = existing user

### Challenges

1. How to capture the semantics on HINs in the meta-learning setting?
    - multifaceted semantic contexts로 해결
2. `multifaceted semantics` (e.g. 같은 감독의 영화, 같은 배우가 출연한 영화 등) → 어떻게 일반화할 것인가? 
    - co-adaption meta-learner로 해결 (semantic wise + task wise)

### Contributions

1. cold-start recommendation을 위해 HIN에 meta-learning을 활용한 첫번째 시도
2. MetaHIN 제안 (multifaceted semantic contexts and a coadaption meta-learner)
3. extensive empirical studies on three real-world datasets on different cold-start scenarios

 

## Preliminaries

### 1. Problem Formulation

**HIN(Heterogeneous Information Network)** 

- G = {V, E, O, R}  if |O| + |R| > 2
    - 즉, graph인데 |O| + |R| 이 2보다 큰 것을 HIN이라고 정의
    - V: node, E: edge, O: object, R: relation

**Meta-path**

- o ∈ O, r ∈ R
    
    ![스크린샷 2021-10-24 오후 10.50.19.png](/assets/posts/스크린샷_2021-10-24_오후_10.50.19.png)
    
    - relation 생략하면 P =o1o2···ol+1으로 쓸 수 있음
- O = {User (U), Movie (M), Actor (A) and Director (D)}
- `UMAM` : 같은 배우가 출연한 영화
- `UMDM` : 같은 감독의 영화

**Cold-start Recommendation**

- `UC` : user cold-start
- `IC`: item cold-start
- `UIC`: user-item cold-start

### 2. Meta-learning for Recommendation

**meta-training**

- $T_u = (S_u, Q_u)$
    - $S_u$ : support set, $Q_u$: query set
- support set으로 task-specific parameter update, query set으로 gloabl θ update
    
    ![스크린샷 2021-10-24 오후 11.02.33.png](/assets/posts/스크린샷_2021-10-24_오후_11.02.33.png)
    

**meta-testing**

- meta-testing 태스크를 어떻게 정의하냐에 따라 3가지 cold-start scenario 테스트 할 수 있음
    - `UC` : user cold-start
    - `IC`: item cold-start
    - `UIC`: user-item cold-start

## Methodology

### 1. Overview of MetaHIN

![스크린샷 2021-10-24 오후 11.09.00.png](/assets/posts/스크린샷_2021-10-24_오후_11.09.00.png)

### 2. Semantic-enhanced Task Constructor

- meta-paths P = {UM, UMAM, UMDM, UMUM}
    
    ![스크린샷 2021-10-25 오후 4.12.43.png](/assets/posts/스크린샷_2021-10-25_오후_4.12.43.png)
    
    - `task`는 `support set`과 `query set`으로 구성
    - `support set`은 user u가 rating한 item set & meta-paths P에 기반한 semantic contexts로 구성
        - 기존 meta-learning 기반 추천 모델의 support set은 direct rating한 item만 봤다면, 이 논문에선 meta-path에 기반한 다른 item들도 봄
- `semantic context of <u,i>`
    
    ![스크린샷 2021-10-25 오후 4.25.15.png](/assets/posts/스크린샷_2021-10-25_오후_4.25.15.png)
    
    - 각 meta-path에 존재하는 모든 item set
    - e.g. meta-path "UMAM"에서 <u2, m2>의 sematic context C는 {m2, m3, ....} 이다. - Fig. 2(a)
- `p-induced semantic context`
    
    ![스크린샷 2021-10-25 오후 4.28.56.png](/assets/posts/스크린샷_2021-10-25_오후_4.28.56.png)
    
    - 위에서 구한 user가 rating한 모든 item의 C(semantic context)의 합집합이 각 meta-path p의 semantic context가 된다.
- `semantic context`
    
    ![스크린샷 2021-10-25 오후 4.31.29.png](/assets/posts/스크린샷_2021-10-25_오후_4.31.29.png)
    
    - 모든 meta-path에 대한 semantic context를 구하면 final semantic context를 얻을 수 있다.
- for `query set`
    
    ![스크린샷 2021-10-25 오후 4.33.51.png]((/assets/posts/스크린샷_2021-10-25_오후_4.33.51.png)
    
    - `support set`과 동일하게 구성
    - 단, support set의 rated item set과 query set의 rated item set은 exclusive
        
        ![스크린샷 2021-10-25 오후 4.36.20.png](/assets/posts/스크린샷_2021-10-25_오후_4.36.20.png)
        

### 3. Co-adaptation Meta-learner

**base model**

![스크린샷 2021-10-25 오후 4.38.29.png](/assets/posts/스크린샷_2021-10-25_오후_4.38.29.png)

- `context aggregation` (=user embedding)
    
    ![스크린샷 2021-10-25 오후 4.42.38.png](/assets/posts/스크린샷_2021-10-25_오후_4.42.38.png)
    
    - **MEAN(·)** is mean pooling
    - **σ** is the activation function (`LeaklyReLU`)
- `preference prediction` (=estimate the rating score)
    
    ![스크린샷 2021-10-25 오후 4.45.15.png](/assets/posts/스크린샷_2021-10-25_오후_4.45.15.png)
    
    - **MLP** is a two-layer multilayer perceptron
    - **⊕** denotes concatenation
- `loss`
    
    ![스크린샷 2021-10-25 오후 4.46.27.png](/assets/posts/스크린샷_2021-10-25_오후_4.46.27.png)
    

**Co-adaptation**

**[Goal]** to learn the prior knowledge θ = (φ, ω)

1. **Semantic-wise Adaptation. (φ 관점)**
    
    ![스크린샷 2021-10-25 오후 4.53.37.png](/assets/posts/스크린샷_2021-10-25_오후_4.53.37.png)
    
    - 각 meta-path p에 대해서 user embedding을 얻을 수가 있음 → 그렇게 구한 embedding으로만 loss 계산
    - gradient descent step
        
        ![스크린샷 2021-10-25 오후 5.03.09.png](/assets/posts/스크린샷_2021-10-25_오후_5.03.09.png)
        
    
2. **Task-wise Adaptation. (ω 관점)**
    
    ![스크린샷 2021-10-25 오후 5.00.39.png](/assets/posts/스크린샷_2021-10-25_오후_5.00.39.png)
    
    - ω에 각 meta-path p에 대해서 구한 user embedding을 element-wise product한 값을 사용
    - gradient descent step
        
        ![스크린샷 2021-10-25 오후 5.03.05.png](/assets/posts/스크린샷_2021-10-25_오후_5.03.05.png)
        

**Optimization**

- `query set`으로 global θ = (φ, ω) update
    
    ![스크린샷 2021-10-25 오후 5.06.04.png](/assets/posts/스크린샷_2021-10-25_오후_5.06.04.png)
    

---

## References

- [Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation]([https://dl.acm.org/doi/pdf/10.1145/3394486.3403207](https://dl.acm.org/doi/pdf/10.1145/3394486.3403207))